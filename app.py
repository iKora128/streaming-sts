"""
Speech-to-Textã¨LLMã‚’é€£æºã•ã›ã‚‹Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
"""
import os
import time
import threading
import queue
import logging
from typing import List, Tuple

import streamlit as st
from dotenv import load_dotenv
import traceback  # ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯æƒ…å ±ã‚’å‡ºåŠ›ã™ã‚‹ãŸã‚ã«è¿½åŠ 

from speech_to_text import SpeechToTextStreaming
from llm_manager import LLMManager

# ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("app.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰é–“ã§å…±æœ‰ï¼‰
_is_listening = False
_transcript_queue = queue.Queue()
_llm_manager = None  # LLMãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦ä¿æŒ
_transcripts = []  # æ–‡å­—èµ·ã“ã—ã‚’ä¿å­˜ã™ã‚‹ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
_responses = []  # å¿œç­”ã‚’ä¿å­˜ã™ã‚‹ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
_current_transcript = ""  # ç¾åœ¨ã®æ–‡å­—èµ·ã“ã—ã‚’ä¿å­˜ã™ã‚‹ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
_current_response = ""  # ç¾åœ¨ç”Ÿæˆä¸­ã®LLMå¿œç­”ã‚’ä¿å­˜ã™ã‚‹ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
_update_ui = False  # UIã®æ›´æ–°ãƒ•ãƒ©ã‚°
_last_ui_update_time = time.time()  # æœ€å¾Œã«UIã‚’æ›´æ–°ã—ãŸæ™‚é–“
_force_update = False  # å¼·åˆ¶æ›´æ–°ãƒ•ãƒ©ã‚°
_is_generating = False  # LLMå¿œç­”ç”Ÿæˆä¸­ãƒ•ãƒ©ã‚°
_accumulated_context = ""  # Global variable to accumulate short-turn transcripts

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®çŠ¶æ…‹ä¿å­˜
_STATE_FILE = "app_state.json"

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "stt" not in st.session_state:
    st.session_state.stt = None

if "llm" not in st.session_state:
    st.session_state.llm = None

if "is_listening" not in st.session_state:
    st.session_state.is_listening = False

if "transcripts" not in st.session_state:
    st.session_state.transcripts = []

if "responses" not in st.session_state:
    st.session_state.responses = []

if "current_transcript" not in st.session_state:
    st.session_state.current_transcript = ""

if "transcript_queue" not in st.session_state:
    st.session_state.transcript_queue = queue.Queue()

if "response_thread" not in st.session_state:
    st.session_state.response_thread = None

if "last_update_time" not in st.session_state:
    st.session_state.last_update_time = time.time()

if "current_response" not in st.session_state:
    st.session_state.current_response = ""

if "is_generating" not in st.session_state:
    st.session_state.is_generating = False

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«åˆ¤å®šçµæœã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®åˆæœŸåŒ–
if 'turn_detection_results' not in st.session_state:
    st.session_state.turn_detection_results = []

# LLMã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
AIZUCHI_SYSTEM_PROMPT = """
ã‚ãªãŸã¯ä¼šè©±ã®ç›¸æ‰‹ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã«å¯¾ã—ã¦ã€ç›¸æ§Œã‚’æ‰“ã¤ã‚ˆã†ã«çŸ­ãè¿”ç­”ã—ã¦ãã ã•ã„ã€‚
ä¾‹ãˆã°ã€Œãªã‚‹ã»ã©ã€ã€Œãã†ã§ã™ã­ã€ã€Œç¢ºã‹ã«ã€ã€Œãã‚Œã¯èˆˆå‘³æ·±ã„ã§ã™ã­ã€ãªã©ã®çŸ­ã„ç›¸æ§Œã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
è¿”ç­”ã¯å¿…ãš1ã€œ3èªç¨‹åº¦ã®çŸ­ã„ç›¸æ§Œã«ã—ã¦ãã ã•ã„ã€‚é•·ã„èª¬æ˜ã‚„è³ªå•ã¯é¿ã‘ã¦ãã ã•ã„ã€‚
"""

CONVERSATION_SYSTEM_PROMPT = """
ã‚ãªãŸã¯ä¼šè©±ã®ç›¸æ‰‹ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã«å¯¾ã—ã¦ã€è‡ªç„¶ãªä¼šè©±ã‚’ç¶šã‘ã‚‹ã‚ˆã†ã«è¿”ç­”ã—ã¦ãã ã•ã„ã€‚
è³ªå•ã«ã¯ç­”ãˆã€æ„è¦‹ã«ã¯å…±æ„Ÿã‚„åˆ¥ã®è¦–ç‚¹ã‚’æä¾›ã—ã€ä¼šè©±ã‚’ç™ºå±•ã•ã›ã¦ãã ã•ã„ã€‚
è¿”ç­”ã¯ç°¡æ½”ã§è‡ªç„¶ãªä¼šè©±èª¿ã«ã—ã¦ãã ã•ã„ã€‚
"""

# ä¼šè©±ã‚¿ãƒ¼ãƒ³åˆ¤å®šç”¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
TURN_DETECTION_PROMPT = """
ã‚ãªãŸã¯ä¼šè©±åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’åˆ†æã—ã€ãã‚ŒãŒå®Œçµã—ãŸç™ºè¨€ã‹ã€ç¶šããŒã‚ã‚‹é€”ä¸­ã®ç™ºè¨€ã‹ã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ç´”ç²‹ãªJSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ä»–ã®èª¬æ˜ã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ï¼š
{
  "continueConversation": true/false,
  "acknowledgement": "é©åˆ‡ãªçŸ­ã„ç›¸æ§Œã‚„è¿”äº‹"
}

åˆ¤æ–­åŸºæº–ï¼š
- "continueConversation": false â†’ ç™ºè¨€ãŒå®Œçµã—ã¦ã„ã‚‹ï¼ˆè³ªå•ã‚„æ„è¦‹ãŒæ˜ç¢ºã«è¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ï¼‰
- "continueConversation": true â†’ ç™ºè¨€ãŒé€”ä¸­ã¾ãŸã¯ç¶šããŒã‚ã‚‹ï¼ˆè¨€ã„ã‹ã‘ã¦æ­¢ã¾ã£ã¦ã„ã‚‹ã€å˜èªã ã‘ã®ç™ºè¨€ãªã©ï¼‰

ä¾‹ï¼š
- ã€Œä»Šæ—¥ã¯ã©ã‚“ãªå¤©æ°—ã§ã™ã‹ï¼Ÿã€â†’ {"continueConversation": false, "acknowledgement": "ä»Šæ—¥ã®å¤©æ°—ã«ã¤ã„ã¦ãŠç­”ãˆã—ã¾ã™"}
- ã€Œä»Šæ—¥ã¯...ã€â†’ {"continueConversation": true, "acknowledgement": "ã¯ã„"}
- ã€Œãã‚Œã£ã¦ã€â†’ {"continueConversation": true, "acknowledgement": "ã¯ã„ï¼Ÿ"}

ä¼šè©±ãŒå®Œçµã—ã¦ã„ã‚‹å ´åˆã¯å¿…ãšfalseã‚’è¿”ã—ã¦ãã ã•ã„ã€‚ç‰¹ã«è³ªå•ã‚„æ˜ç¢ºãªæ„è¦‹è¡¨æ˜ãŒã‚ã£ãŸå ´åˆã¯å¿…ãšfalseã§ã™ã€‚
"""

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®å®šç¾©
_state_lock = threading.RLock()  # ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªæ“ä½œã®ãŸã‚ã®ãƒ­ãƒƒã‚¯

# å®Ÿé¨“çš„ãªæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
st.set_page_config(
    page_title="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ä¼šè©±",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'About': "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ä¼šè©±ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"
    }
)

# æ›´æ–°é–“éš”ã‚’çŸ­ãã™ã‚‹ï¼ˆå®Ÿé¨“çš„ï¼‰
if "update_frequency" not in st.session_state:
    st.session_state.update_frequency = 0.1  # 100ãƒŸãƒªç§’ã”ã¨ã«æ›´æ–°

def initialize_stt():
    """
    Speech-to-Textã®åˆæœŸåŒ–
    """
    project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
    if not project_id:
        error_msg = "ç’°å¢ƒå¤‰æ•°GOOGLE_CLOUD_PROJECTãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        logger.error(error_msg)
        st.error(error_msg)
        return None
    
    try:
        logger.info(f"Speech-to-Textã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID: {project_id}")
        stt = SpeechToTextStreaming(
            project_id=project_id,
            language_code="ja-JP",
            use_short_model=False
        )
        logger.info("Speech-to-Textã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        return stt
    except Exception as e:
        error_msg = f"Speech-to-Textã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        logger.error(error_msg)
        st.error(error_msg)
        return None

def initialize_llm():
    """
    LLMã®åˆæœŸåŒ–
    """
    global _llm_manager
    try:
        logger.info("LLMã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚")
        llm = LLMManager()
        _llm_manager = llm  # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ä¿å­˜
        logger.info("LLMã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        return llm
    except Exception as e:
        error_msg = f"LLMã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        logger.error(error_msg)
        st.error(error_msg)
        return None

def on_speech_result(transcript: str, is_final: bool):
    """
    éŸ³å£°èªè­˜çµæœã‚’å—ã‘å–ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
    
    Args:
        transcript: èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        is_final: æœ€çµ‚çµæœã‹ã©ã†ã‹
    """
    global _transcript_queue, _current_transcript, _update_ui, _last_ui_update_time
    
    # ç¾åœ¨ã®æ–‡å­—èµ·ã“ã—ã‚’æ›´æ–°
    _current_transcript = transcript
    
    # ãƒ­ã‚°å‡ºåŠ›
    if is_final:
        logger.info(f"éŸ³å£°èªè­˜çµæœï¼ˆæœ€çµ‚ï¼‰: {transcript}")
    else:
        logger.debug(f"éŸ³å£°èªè­˜çµæœï¼ˆä¸­é–“ï¼‰: {transcript}")
    
    # æœ€çµ‚çµæœã®å ´åˆã¯ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
    if is_final and transcript.strip():
        _transcript_queue.put(transcript)
        _update_ui = True  # UIã®æ›´æ–°ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        _last_ui_update_time = time.time()  # æœ€å¾Œã®æ›´æ–°æ™‚é–“ã‚’è¨˜éŒ²

def on_llm_stream(chunk: str):
    """
    LLMã‹ã‚‰ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’å‡¦ç†ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
    
    Args:
        chunk: LLMã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯
    """
    global _current_response, _update_ui, _last_ui_update_time, _force_update, _is_generating
    
    if chunk:
        _current_response += chunk
        _update_ui = True
        _last_ui_update_time = time.time()
        
        try:
            # ã“ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
            st.session_state.current_response = _current_response
            # å¼·åˆ¶æ›´æ–°è¦æ±‚
            _force_update = True
        except Exception as e:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–ï¼ˆåˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã§ç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ã‚ã‚Šï¼‰
            logger.warning(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®æ›´æ–°ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            pass
    
    logger.debug(f"LLMã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°: {chunk}")  # è©³ç´°ãªãƒ­ã‚°

def _save_state():
    """çŠ¶æ…‹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    state = {
        "transcripts": _transcripts,
        "responses": _responses,
        "current_transcript": _current_transcript,
        "current_response": _current_response,
        "turn_detection_results": st.session_state.get("turn_detection_results", [])  # è¿½åŠ 
    }
    
    with open(_STATE_FILE, "w", encoding="utf-8") as f:
        import json
        json.dump(state, f, ensure_ascii=False, indent=2)

def _load_state():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã‚€"""
    import json  # jsonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã“ã“ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    
    if os.path.exists(_STATE_FILE):
        try:
            with open(_STATE_FILE, "r", encoding="utf-8") as f:
                state = json.load(f)
            
            # æ—¢å­˜ã®çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã‚€
            _transcripts = state.get("transcripts", [])
            _responses = state.get("responses", [])
            _current_transcript = state.get("current_transcript", "")
            _current_response = state.get("current_response", "")
            
            # ã‚¿ãƒ¼ãƒ³åˆ¤å®šçµæœã®èª­ã¿è¾¼ã¿
            if "turn_detection_results" in state:
                st.session_state.turn_detection_results = state["turn_detection_results"]
            
            logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚è»¢è¨˜æ•°: {len(_transcripts)}, å¿œç­”æ•°: {len(_responses)}")
            return _transcripts, _responses
        except Exception as e:
            logger.error(f"çŠ¶æ…‹ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    return [], []

def process_transcripts():
    """
    éŸ³å£°èªè­˜çµæœã‚’å‡¦ç†ã™ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰é–¢æ•°
    """
    global _is_listening, _transcript_queue, _llm_manager, _transcripts, _responses, _update_ui, _last_ui_update_time, _force_update, _current_response, _is_generating, _accumulated_context
    
    logger.info("æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    import json
    import re
    
    while _is_listening:
        try:
            if not _transcript_queue.empty():
                # æ–‡å­—èµ·ã“ã—ã‚’å–å¾—ã—ãŸå¾Œ
                transcript = _transcript_queue.get(timeout=0.1)
                logger.info(f"ã‚­ãƒ¥ãƒ¼ã‹ã‚‰å–å¾—ã—ãŸæ–‡å­—èµ·ã“ã—: {transcript}")
                
                # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ä¿å­˜ï¼ˆã“ã‚Œã¯ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ï¼‰
                global _current_transcript
                _current_transcript = transcript
                
                # LLMã‚’ä½¿ç”¨ã—ã¦ã‚¿ãƒ¼ãƒ³åˆ¤å®š
                turn_response = _llm_manager.call_model(
                    prompt=transcript,
                    system_prompt=TURN_DETECTION_PROMPT,
                    model="gemini-2.0-flash-lite",
                    stream=False
                )
                logger.info(f"ã‚¿ãƒ¼ãƒ³åˆ¤å®šçµæœ: {turn_response}")
                
                # æ”¹å–„ã•ã‚ŒãŸJSONãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½¿ç”¨
                continue_conversation, ack = parse_turn_decision(turn_response, transcript)
                logger.info(f"è§£æçµæœ: ä¼šè©±ç¶™ç¶š={continue_conversation}, ç›¸æ§Œ=\"{ack}\"")
                
                # åˆ¤å®šçµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                turn_result = {
                    "transcript": transcript,
                    "continue_conversation": continue_conversation,
                    "acknowledgement": ack,
                    "raw_response": turn_response,
                    "timestamp": time.time()
                }
                
                # ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã«çŠ¶æ…‹ã‚’æ›´æ–°
                with _state_lock:
                    # æœ€å¤§10ä»¶ã¾ã§ä¿å­˜
                    if "turn_detection_results" not in st.session_state:
                        st.session_state.turn_detection_results = []
                    
                    if len(st.session_state.turn_detection_results) >= 10:
                        st.session_state.turn_detection_results.pop(0)
                    st.session_state.turn_detection_results.append(turn_result)
                    _save_state()  # çŠ¶æ…‹ã‚’ä¿å­˜
                
                # ä¼šè©±çŠ¶æ…‹ã®æ›´æ–°ã¨å¿œç­”å‡¦ç†
                if continue_conversation:
                    # ä¼šè©±ç¶™ç¶šã®å ´åˆã¯ç›¸æ§Œã‚’è¿”ã™
                    logger.info(f"ä¼šè©±ç¶™ç¶šã¨åˆ¤æ–­: ç›¸æ§Œ=\"{ack}\"")
                    
                    # ç›¸æ§Œã‚’è¡¨ç¤ºã™ã‚‹ã ã‘ã§ã€LLMå¿œç­”ã¯ç”Ÿæˆã—ãªã„
                    with _state_lock:
                        _current_transcript = transcript
                        _current_response = ack
                        _update_ui = True
                        _last_ui_update_time = time.time()
                else:
                    # ä¼šè©±å®Œäº†ã®å ´åˆã¯LLMå¿œç­”ã‚’ç”Ÿæˆ
                    logger.info("ä¼šè©±å®Œäº†ã¨åˆ¤æ–­: å¿œç­”ç”Ÿæˆé–‹å§‹")
                    _is_generating = True
                    
                    try:
                        # LLMå¿œç­”ã®ç”Ÿæˆ
                        response_text = ""
                        
                        # ä¼šè©±å±¥æ­´ã‚’æ§‹ç¯‰
                        conversation_history = ""
                        for i in range(min(len(_transcripts), len(_responses))):
                            conversation_history += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {_transcripts[i]}\nAI: {_responses[i]}\n"
                        
                        # ç¾åœ¨ã®ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
                        current_context = f"{conversation_history}ãƒ¦ãƒ¼ã‚¶ãƒ¼: {transcript}\nAI: "
                        
                        # LLMå¿œç­”ã®ç”Ÿæˆï¼ˆãƒ¢ãƒ‡ãƒ«åã‚’ä¿®æ­£ï¼‰
                        response_text = _llm_manager.call_model(
                            prompt=current_context,
                            system_prompt=CONVERSATION_SYSTEM_PROMPT,
                            model="gemini-2.0-flash-lite", 
                            stream=False
                        )
                        
                        logger.info(f"LLMå¿œç­”ç”Ÿæˆå®Œäº†: {response_text[:100]}...")
                        
                        # å¿œç­”ã‚’ä¿å­˜
                        with _state_lock:
                            _transcripts.append(transcript)
                            _responses.append(response_text)
                            _current_transcript = transcript
                            _current_response = response_text
                            _update_ui = True
                            _force_update = True
                            _last_ui_update_time = time.time()
                            _save_state()
                    except Exception as e:
                        logger.error(f"LLMå¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                        logger.error(str(e))
                        traceback.print_exc()
                    finally:
                        _is_generating = False
        except Exception as e:
            logger.error(f"æ–‡å­—èµ·ã“ã—ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            logger.error(str(e))
            traceback.print_exc()
        
        time.sleep(0.1)  # CPUã®ä½¿ç”¨ç‡ã‚’ä¸‹ã’ã‚‹ãŸã‚ã«çŸ­ã„ã‚¹ãƒªãƒ¼ãƒ—

def parse_turn_decision(turn_response, transcript):
    """
    LLMã‚’ä¸»ä½“ã¨ã—ãŸã‚¿ãƒ¼ãƒ³åˆ¤å®šè§£æå™¨ï¼ˆãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã¯ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ã¿ï¼‰
    """
    import json
    import re
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    continue_conversation = True
    ack = "ãªã‚‹ã»ã©"
    
    # 1. LLMå¿œç­”ã‹ã‚‰JSONã‚’ç›´æ¥è§£æï¼ˆãƒ¡ã‚¤ãƒ³æ–¹æ³•ï¼‰
    try:
        json_match = re.search(r'\{.*\}', turn_response, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            turn_data = json.loads(json_str)
            continue_conversation = turn_data.get("continueConversation", True)
            ack = turn_data.get("acknowledgement", "ãªã‚‹ã»ã©")
            logger.info(f"LLMåˆ¤å®šã‚’ä½¿ç”¨: {continue_conversation}")
            return continue_conversation, ack
    except Exception as e:
        logger.warning(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # 2. æ­£è¦è¡¨ç¾ã§å€‹åˆ¥ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æŠ½å‡ºï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—1ï¼‰
    try:
        continue_match = re.search(r'"continueConversation"\s*:\s*(true|false)', turn_response)
        ack_match = re.search(r'"acknowledgement"\s*:\s*"([^"]+)"', turn_response)
        
        if continue_match:
            continue_conversation = continue_match.group(1).lower() == "true"
            logger.info(f"continueConversationæ­£è¦è¡¨ç¾æŠ½å‡º: {continue_conversation}")
        
        if ack_match:
            ack = ack_match.group(1)
            logger.info(f"acknowledgementæ­£è¦è¡¨ç¾æŠ½å‡º: {ack}")
        
        if continue_match:  # continueConversationã®å€¤ãŒæŠ½å‡ºã§ãã¦ã„ã‚Œã°OK
            return continue_conversation, ack
    except Exception as e:
        logger.warning(f"æ­£è¦è¡¨ç¾æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # 3. LLMå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆå†…ã®å˜èªã«åŸºã¥ãç°¡æ˜“åˆ¤å®šï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—2ï¼‰
    # ã“ã‚Œã¯ã¾ã LLMã®å¿œç­”ã«åŸºã¥ã„ã¦ã„ã‚‹
    if "true" in turn_response.lower():
        continue_conversation = True
        logger.info("å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆå†…ã®'true'ã«åŸºã¥ãä¼šè©±ç¶™ç¶šã¨åˆ¤å®š")
    elif "false" in turn_response.lower():
        continue_conversation = False
        logger.info("å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆå†…ã®'false'ã«åŸºã¥ãä¼šè©±å®Œäº†ã¨åˆ¤å®š")
    
    # æœ€å¾Œã«è³ªå•æ¤œå‡ºã ã‘ã¯ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼ˆé‡è¦ãªã‚±ãƒ¼ã‚¹ï¼‰
    if "?" in transcript or "ï¼Ÿ" in transcript or any(q in transcript for q in ["ä½•", "ã©ã†", "ãªãœ", "ã„ã¤", "ã©ã“", "ã ã‚Œ", "èª°", "ã§ã™ã‹"]):
        continue_conversation = False
        logger.info("è³ªå•æ¤œå‡ºã«ã‚ˆã‚‹ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰: ä¼šè©±å®Œäº†")
    
    return continue_conversation, ack

def start_listening():
    """
    éŸ³å£°èªè­˜ã‚’é–‹å§‹ã™ã‚‹
    """
    global _is_listening
    
    if st.session_state.is_listening:
        logger.info("ã™ã§ã«éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¦ã„ã¾ã™ã€‚")
        return
    
    logger.info("éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    
    # Speech-to-Textã®åˆæœŸåŒ–
    if not st.session_state.stt:
        logger.info("Speech-to-Textã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚")
        st.session_state.stt = initialize_stt()
    
    # LLMã®åˆæœŸåŒ–
    if not st.session_state.llm:
        logger.info("LLMã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚")
        st.session_state.llm = initialize_llm()
    
    if not st.session_state.stt or not st.session_state.llm:
        error_msg = "åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
        logger.error(error_msg)
        st.error(error_msg)
        return
    
    # éŸ³å£°èªè­˜ã‚’é–‹å§‹
    logger.info("ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    st.session_state.stt.start_listening(callback=on_speech_result)
    st.session_state.is_listening = True
    _is_listening = True
    
    # æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
    logger.info("æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    st.session_state.response_thread = threading.Thread(target=process_transcripts)
    st.session_state.response_thread.daemon = True
    st.session_state.response_thread.start()

def stop_listening():
    """
    éŸ³å£°èªè­˜ã‚’åœæ­¢ã™ã‚‹
    """
    global _is_listening
    
    if not st.session_state.is_listening:
        logger.info("éŸ³å£°èªè­˜ã¯ã™ã§ã«åœæ­¢ã—ã¦ã„ã¾ã™ã€‚")
        return
    
    logger.info("éŸ³å£°èªè­˜ã‚’åœæ­¢ã—ã¾ã™ã€‚")
    
    # éŸ³å£°èªè­˜ã‚’åœæ­¢
    if st.session_state.stt:
        st.session_state.stt.stop_listening()
    
    st.session_state.is_listening = False
    _is_listening = False
    
    # ã‚¹ãƒ¬ãƒƒãƒ‰ãŒçµ‚äº†ã™ã‚‹ã®ã‚’å¾…æ©Ÿ
    if st.session_state.response_thread and st.session_state.response_thread.is_alive():
        logger.info("æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…æ©Ÿã—ã¾ã™ã€‚")
        st.session_state.response_thread.join(timeout=1.0)
    
    logger.info("éŸ³å£°èªè­˜ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚")

def clear_history():
    """
    ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹
    """
    global _transcript_queue, _transcripts, _responses, _current_transcript, _update_ui, _accumulated_context
    
    logger.info("ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™ã€‚")
    
    _transcripts = []
    _responses = []
    _current_transcript = ""
    _accumulated_context = ""  # è“„ç©ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚‚ã‚¯ãƒªã‚¢
    
    # ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢
    while not _transcript_queue.empty():
        _transcript_queue.get()
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚‚æ›´æ–°
    st.session_state.transcripts = []
    st.session_state.responses = []
    st.session_state.current_transcript = ""
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«çŠ¶æ…‹ã‚’ä¿å­˜
    _save_state()
    
    _update_ui = True
    
    logger.info("ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")

def update_session_state():
    """
    ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°ã™ã‚‹
    """
    global _transcripts, _responses, _current_transcript, _current_response, _force_update, _is_generating
    
    logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°ã—ã¾ã™ã€‚è»¢è¨˜æ•°: {len(_transcripts)}, å¿œç­”æ•°: {len(_responses)}")
    
    # è»¢è¨˜ã¨å¿œç­”ã®æ•°ãŒä¸€è‡´ã—ãªã„å ´åˆã¯èª¿æ•´
    if len(_transcripts) > len(_responses):
        logger.warning(f"è»¢è¨˜æ•°({len(_transcripts)})ãŒå¿œç­”æ•°({len(_responses)})ã‚ˆã‚Šå¤šã„ã§ã™ã€‚èª¿æ•´ã—ã¾ã™ã€‚")
        _transcripts = _transcripts[:len(_responses)]
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ€æ–°ã®çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã‚€
    _load_state()
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
    st.session_state.transcripts = _transcripts.copy()
    st.session_state.responses = _responses.copy()
    st.session_state.current_transcript = _current_transcript
    st.session_state.current_response = _current_response
    st.session_state.is_generating = _is_generating
    st.session_state.last_update_time = time.time()
    _force_update = False
    
    logger.info(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚st.session_state.transcripts: {len(st.session_state.transcripts)}, st.session_state.responses: {len(st.session_state.responses)}")

def save_conversation_to_html():
    """
    ä¼šè©±å±¥æ­´ã‚’HTMLå½¢å¼ã§ä¿å­˜ã™ã‚‹
    """
    global _transcripts, _responses
    
    if not _transcripts or not _responses:
        logger.info("ä¿å­˜ã™ã‚‹ä¼šè©±å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return None
    
    try:
        # HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        html_template = """
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>ä¼šè©±å±¥æ­´</title>
            <style>
                body {
                    font-family: Arial, sans-serif;
                    max-width: 800px;
                    margin: 0 auto;
                    padding: 20px;
                    background-color: #f5f5f5;
                }
                .chat-container {
                    display: flex;
                    flex-direction: column;
                    gap: 15px;
                }
                .message {
                    display: flex;
                    margin-bottom: 10px;
                }
                .user-message {
                    justify-content: flex-end;
                }
                .ai-message {
                    justify-content: flex-start;
                }
                .message-bubble {
                    max-width: 70%;
                    padding: 10px 15px;
                    border-radius: 18px;
                    box-shadow: 0 1px 2px rgba(0,0,0,0.1);
                }
                .user-bubble {
                    background-color: #dcf8c6;
                    border-bottom-right-radius: 5px;
                }
                .ai-bubble {
                    background-color: #ffffff;
                    border-bottom-left-radius: 5px;
                }
                .timestamp {
                    font-size: 0.7em;
                    color: #999;
                    margin-top: 5px;
                    text-align: right;
                }
                h1 {
                    text-align: center;
                    color: #333;
                }
            </style>
        </head>
        <body>
            <h1>ä¼šè©±å±¥æ­´</h1>
            <div class="chat-container">
                {chat_content}
            </div>
        </body>
        </html>
        """
        
        # ä¼šè©±å†…å®¹ã‚’ç”Ÿæˆ
        chat_content = ""
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        
        for i in range(len(_transcripts)):
            # HTMLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†
            user_text = _transcripts[i].replace("<", "&lt;").replace(">", "&gt;")
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            chat_content += f"""
            <div class="message user-message">
                <div class="message-bubble user-bubble">
                    <div>{user_text}</div>
                    <div class="timestamp">{timestamp}</div>
                </div>
            </div>
            """
            
            # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if i < len(_responses):
                # HTMLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†
                ai_text = _responses[i].replace("<", "&lt;").replace(">", "&gt;")
                
                chat_content += f"""
                <div class="message ai-message">
                    <div class="message-bubble ai-bubble">
                        <div>{ai_text}</div>
                        <div class="timestamp">{timestamp}</div>
                    </div>
                </div>
                """
        
        # HTMLã‚’ç”Ÿæˆ
        html_content = html_template.format(chat_content=chat_content)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
        filename = f"conversation_{time.strftime('%Y%m%d_%H%M%S')}.html"
        
        # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        with open(filename, "w", encoding="utf-8") as f:
            f.write(html_content)
        
        logger.info(f"ä¼šè©±å±¥æ­´ã‚’HTMLãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
        return filename
    except Exception as e:
        error_msg = f"ä¼šè©±å±¥æ­´ã®HTMLä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        logger.error(error_msg)
        return None

def main():
    """
    ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "transcripts" not in st.session_state:
        st.session_state.transcripts = []
    if "responses" not in st.session_state:
        st.session_state.responses = []
    if "current_transcript" not in st.session_state:
        st.session_state.current_transcript = ""
    if "current_response" not in st.session_state:
        st.session_state.current_response = ""
    if "is_listening" not in st.session_state:
        st.session_state.is_listening = False
    if "is_generating" not in st.session_state:
        st.session_state.is_generating = False
    if "last_update_time" not in st.session_state:
        st.session_state.last_update_time = time.time()
    # ã“ã“ã«è¿½åŠ  - ã‚¿ãƒ¼ãƒ³åˆ¤å®šçµæœã®åˆæœŸåŒ–
    if "turn_detection_results" not in st.session_state:
        st.session_state.turn_detection_results = []
    
    global _transcripts, _responses, _current_transcript, _current_response, _update_ui, _last_ui_update_time, _force_update, _is_generating
    
    logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    
    st.title("ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ä¼šè©±")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã‚€
    _load_state()
    
    # èµ·å‹•æ™‚ã«ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°
    update_session_state()
    logger.info(f"èµ·å‹•æ™‚ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚è»¢è¨˜æ•°: {len(st.session_state.transcripts)}, å¿œç­”æ•°: {len(st.session_state.responses)}")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("è¨­å®š")
        
        # éŸ³å£°èªè­˜ã®é–‹å§‹/åœæ­¢ãƒœã‚¿ãƒ³
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ¤ éŒ²éŸ³é–‹å§‹", use_container_width=True, disabled=st.session_state.is_listening):
                logger.info("éŒ²éŸ³é–‹å§‹ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚")
                start_listening()
                st.rerun()  # UIã‚’å³æ™‚æ›´æ–°
        
        with col2:
            if st.button("â¹ï¸ éŒ²éŸ³åœæ­¢", use_container_width=True, disabled=not st.session_state.is_listening):
                logger.info("éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚")
                stop_listening()
                st.rerun()  # UIã‚’å³æ™‚æ›´æ–°
        
        # å±¥æ­´ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
        if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚¯ãƒªã‚¢", use_container_width=True):
            logger.info("å±¥æ­´ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚")
            clear_history()
            st.rerun()  # UIã‚’å³æ™‚æ›´æ–°
        
        # ä¼šè©±å±¥æ­´ä¿å­˜ãƒœã‚¿ãƒ³
        if st.button("ğŸ’¾ ä¼šè©±å±¥æ­´ã‚’ä¿å­˜", use_container_width=True):
            logger.info("ä¼šè©±å±¥æ­´ä¿å­˜ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚")
            filename = save_conversation_to_html()
            if filename:
                st.success(f"ä¼šè©±å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
            else:
                st.error("ä¼šè©±å±¥æ­´ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        
        # æ‰‹å‹•æ›´æ–°ãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ ç”»é¢æ›´æ–°", use_container_width=True):
            logger.info("ç”»é¢æ›´æ–°ãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã¾ã—ãŸã€‚")
            update_session_state()
            st.rerun()  # UIã‚’å³æ™‚æ›´æ–°
        
        # è‡ªå‹•æ›´æ–°ã®è¨­å®š
        auto_refresh = st.checkbox("è‡ªå‹•æ›´æ–°ï¼ˆ1ç§’ã”ã¨ï¼‰", value=True)
        
        # æ›´æ–°ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿
        if _update_ui:
            st.success("æ–°ã—ã„ä¼šè©±ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸï¼")
        
        st.divider()
        
        # çŠ¶æ…‹è¡¨ç¤º
        st.subheader("çŠ¶æ…‹")
        st.write(f"éŒ²éŸ³ä¸­: {'ã¯ã„' if st.session_state.is_listening else 'ã„ã„ãˆ'}")
        st.write(f"å¿œç­”ç”Ÿæˆä¸­: {'ã¯ã„' if st.session_state.is_generating else 'ã„ã„ãˆ'}")
        st.write(f"æœ€çµ‚æ›´æ–°: {time.strftime('%H:%M:%S', time.localtime(st.session_state.last_update_time))}")
        
        # ãƒ­ã‚°è¡¨ç¤º
        st.subheader("ãƒ­ã‚°")
        if os.path.exists("app.log"):
            with open("app.log", "r") as f:
                log_content = f.read()
                st.text_area("æœ€æ–°ã®ãƒ­ã‚°", log_content[-5000:], height=200)
        
        st.divider()
        
        # ä½¿ã„æ–¹
        st.subheader("ä½¿ã„æ–¹")
        st.markdown("""
        1. ã€ŒéŒ²éŸ³é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦éŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¾ã™ã€‚
        2. ãƒã‚¤ã‚¯ã«å‘ã‹ã£ã¦è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚
        3. AIãŒè‡ªå‹•çš„ã«ä¼šè©±ã‚’ç¶™ç¶šã™ã‚‹ã‹ç›¸æ§Œã‚’æ‰“ã¤ã‹åˆ¤æ–­ã—ã¾ã™ã€‚
        4. ã€ŒéŒ²éŸ³åœæ­¢ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦éŸ³å£°èªè­˜ã‚’åœæ­¢ã—ã¾ã™ã€‚
        5. ã€Œå±¥æ­´ã‚¯ãƒªã‚¢ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™ã€‚
        6. ã€Œä¼šè©±å±¥æ­´ã‚’ä¿å­˜ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦HTMLå½¢å¼ã§ä¿å­˜ã—ã¾ã™ã€‚
        """)
        
        # ã‚¿ãƒ¼ãƒ³åˆ¤å®šçµæœè¡¨ç¤ºã®åˆ‡ã‚Šæ›¿ãˆï¼ˆæ–°è¦è¿½åŠ ï¼‰
        show_turn_detection = st.checkbox("ã‚¿ãƒ¼ãƒ³åˆ¤å®šçµæœã‚’è¡¨ç¤º", value=True)
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    st.title("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ä¼šè©±")
    
    # ã‚¿ãƒ–ã‚’ä½¿ã£ã¦è¡¨ç¤ºã‚’åˆ†ã‘ã‚‹
    tab1, tab2, tab3 = st.tabs(["ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¼šè©±", "ğŸ”„ ã‚¿ãƒ¼ãƒ³åˆ¤å®š", "ğŸ“ ä¼šè©±å±¥æ­´"])
    
    with tab1:
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¼šè©±è¡¨ç¤º
        st.subheader("ç¾åœ¨ã®ä¼šè©±")
        
        # éŒ²éŸ³çŠ¶æ…‹ã®è¡¨ç¤º
        if st.session_state.is_listening:
            st.info("ğŸ¤ éŒ²éŸ³ä¸­... ãƒã‚¤ã‚¯ã«å‘ã‹ã£ã¦è©±ã—ã‹ã‘ã¦ãã ã•ã„")
            
            # æœ€æ–°ã®ã‚¿ãƒ¼ãƒ³åˆ¤å®šçµæœãŒã‚ã‚Œã°è¡¨ç¤º
            if "turn_detection_results" in st.session_state and st.session_state.turn_detection_results:
                latest_result = st.session_state.turn_detection_results[-1]
                st.markdown(
                    f"""
                    <div style="padding: 10px; border-radius: 5px; background-color: #f0f2f6; margin-bottom: 10px;">
                        <strong>ã‚ãªãŸ (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ):</strong> {latest_result["transcript"]}
                    </div>
                    """, 
                    unsafe_allow_html=True
                )
                
                # ç›¸æ§Œã¾ãŸã¯å¿œç­”ã‚’è¡¨ç¤º
                st.markdown(
                    f"""
                    <div style="padding: 10px; border-radius: 5px; background-color: #e6f7ff; margin-bottom: 10px;">
                        <strong>AI (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ):</strong> {latest_result["acknowledgement"]}
                    </div>
                    """, 
                    unsafe_allow_html=True
                )
        else:
            st.warning("â¸ï¸ éŒ²éŸ³åœæ­¢ä¸­")
        
        # ç¾åœ¨ã®æ–‡å­—èµ·ã“ã—ã¨å¿œç­”ã‚’è¡¨ç¤º
        if st.session_state.current_transcript:
            st.markdown(
                f"""
                <div style="padding: 10px; border-radius: 5px; background-color: #f0f2f6; margin-bottom: 10px;">
                    <strong>ã‚ãªãŸ:</strong> {st.session_state.current_transcript}
                </div>
                """, 
                unsafe_allow_html=True
            )
        
        if st.session_state.current_response:
            st.markdown(
                f"""
                <div style="padding: 10px; border-radius: 5px; background-color: #e6f7ff; margin-bottom: 10px;">
                    <strong>AI:</strong> {st.session_state.current_response}
                </div>
                """, 
                unsafe_allow_html=True
            )
    
    with tab2:
        # ã‚¿ãƒ¼ãƒ³åˆ¤å®šçµæœã®è¡¨ç¤º
        st.subheader("ã‚¿ãƒ¼ãƒ³åˆ¤å®šçµæœ")
        
        # éŒ²éŸ³ä¸­ã®å ´åˆã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æƒ…å ±ã‚’è¡¨ç¤º
        if st.session_state.is_listening:
            st.info("ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¿ãƒ¼ãƒ³åˆ¤å®šä¸­...")
        
        if "turn_detection_results" in st.session_state and st.session_state.turn_detection_results:
            for result in reversed(st.session_state.turn_detection_results):
                continue_val = result["continue_conversation"]
                color = "green" if continue_val else "red"
                icon = "ğŸ”„" if continue_val else "âœ…"
                
                # æœ€æ–°ã®çµæœã«ã¯ã€Œãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã€ãƒãƒ¼ã‚¯ã‚’ä»˜ã‘ã‚‹
                is_latest = (result == st.session_state.turn_detection_results[-1])
                latest_mark = "âš¡ æœ€æ–°: " if is_latest else ""
                
                st.markdown(
                    f"""
                    <div style="margin-bottom:10px; padding:10px; border-left:4px solid {color}; background-color:rgba({0 if continue_val else 255}, {255 if continue_val else 0}, 0, 0.1)">
                        <strong>{icon} {latest_mark}{"ä¼šè©±ç¶™ç¶š" if continue_val else "ä¼šè©±å®Œäº†"}:</strong> {result["transcript"]}
                        <br><small>ç›¸æ§Œ: "{result["acknowledgement"]}"</small>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
        else:
            st.info("ã¾ã ã‚¿ãƒ¼ãƒ³åˆ¤å®šçµæœã¯ã‚ã‚Šã¾ã›ã‚“")
    
    with tab3:
        # ä¼šè©±å±¥æ­´ã®è¡¨ç¤º
        st.subheader("ä¼šè©±å±¥æ­´")
        
        if st.session_state.transcripts and st.session_state.responses:
            for i in range(min(len(st.session_state.transcripts), len(st.session_state.responses))):
                st.markdown(
                    f"""
                    <div style="padding: 10px; border-radius: 5px; background-color: #f0f2f6; margin-bottom: 5px;">
                        <strong>ã‚ãªãŸ:</strong> {st.session_state.transcripts[i]}
                    </div>
                    <div style="padding: 10px; border-radius: 5px; background-color: #e6f7ff; margin-bottom: 15px;">
                        <strong>AI:</strong> {st.session_state.responses[i]}
                    </div>
                    """, 
                    unsafe_allow_html=True
                )
        else:
            st.info("ã¾ã ä¼šè©±å±¥æ­´ã¯ã‚ã‚Šã¾ã›ã‚“")

    # UIã®æ›´æ–°ã‚’å‡¦ç†ã™ã‚‹ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
    ui_placeholder = st.empty()
    
    # å®šæœŸçš„ãªæ›´æ–°ã®ãŸã‚ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    if "update_counter" not in st.session_state:
        st.session_state.update_counter = 0
    
    # å®šæœŸçš„ã«æ›´æ–°ï¼ˆã“ã‚Œã¯ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œã•ã‚Œã‚‹ï¼‰
    st.session_state.update_counter += 1
    
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«å€¤ã‚’ã‚³ãƒ”ãƒ¼
    if _current_transcript:
        st.session_state.current_transcript = _current_transcript
    if _current_response:
        st.session_state.current_response = _current_response

if __name__ == "__main__":
    logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ã—ã¾ã™ã€‚")
    main() 