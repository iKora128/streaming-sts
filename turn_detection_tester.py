"""
ã‚¿ãƒ¼ãƒ³åˆ¤å®šãƒ†ã‚¹ã‚¿ãƒ¼ - ä¼šè©±ã®ç¶™ç¶š/çµ‚äº†åˆ¤å®šã‚’è¦–è¦šåŒ–ã™ã‚‹Streamlitãƒ„ãƒ¼ãƒ«
"""
import os
import re
import json
import streamlit as st
from dotenv import load_dotenv

# LLMãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from llm_manager import LLMManager

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ã‚¿ãƒ¼ãƒ³åˆ¤å®šç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
TURN_DETECTION_PROMPT = """
ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’åˆ†æã—ã€ä¼šè©±ã®æµã‚Œã‚’åˆ¤æ–­ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ãŒä¼šè©±ã®é€”ä¸­ã§ã‚ã‚‹ã‹å®Œäº†ã—ã¦ã„ã‚‹ã‹ã‚’åˆ¤æ–­ã—ã€é©åˆ‡ãªå¿œç­”æ–¹æ³•ã‚’æ±ºå®šã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ä»–ã®èª¬æ˜ã¯ä¸€åˆ‡ä¸è¦ã§ã™ã€‚
{
  "continueConversation": true ã¾ãŸã¯ false,
  "acknowledgement": "é©åˆ‡ãªçŸ­ã„ç›¸æ§Œã‚„è¿”äº‹",
  "reason": "åˆ¤æ–­ç†ç”±ã®çŸ­ã„èª¬æ˜"
}

- continueConversation: 
  - true: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ãŒä¸€æ™‚åœæ­¢ã—ã¦ã„ã‚‹ãŒã€ã¾ã ç™ºè¨€ã®é€”ä¸­ã§ç¶šããŒäºˆæƒ³ã•ã‚Œã‚‹å ´åˆ
  - false: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ãŒå®Œçµã—ã¦ã„ã¦ã€AIãŒå¿œç­”ã™ã¹ãå ´åˆ

- acknowledgement:
  - continueConversationãŒtrueã®å ´åˆ: "ãªã‚‹ã»ã©", "ã¯ã„", "ãˆãˆ" ãªã©ã®éå¸¸ã«çŸ­ã„ç›¸æ§Œ
  - continueConversationãŒfalseã®å ´åˆ: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã«å¯¾ã™ã‚‹é©åˆ‡ãªå¿œç­”ã®å§‹ã¾ã‚Š

- reason:
  - ã“ã®åˆ¤æ–­ã«è‡³ã£ãŸç†ç”±ã®çŸ­ã„èª¬æ˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰

ä¾‹ï¼š
ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼šã€Œä»Šæ—¥ã¯å¤©æ°—ãŒã€
å‡ºåŠ›ï¼š{"continueConversation": true, "acknowledgement": "ã¯ã„", "reason": "æ–‡ãŒé€”ä¸­ã§çµ‚ã‚ã£ã¦ã„ã‚‹"}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼šã€Œä»Šæ—¥ã¯å¤©æ°—ãŒè‰¯ã„ã§ã™ã­ã€
å‡ºåŠ›ï¼š{"continueConversation": false, "acknowledgement": "ãã†ã§ã™ã­ã€ã¨ã¦ã‚‚è‰¯ã„å¤©æ°—ã§ã™", "reason": "å®Œçµã—ãŸæ–‡ã§æ„è¦‹ãŒè¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹"}
"""

def backup_heuristic_analysis(text):
    """
    ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯åˆ†æï¼ˆLLMè§£æãŒå¤±æ•—ã—ãŸå ´åˆï¼‰
    """
    # æ—¥æœ¬èªç”¨ã®ç°¡æ˜“ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯
    has_question_mark = "?" in text or "ï¼Ÿ" in text
    is_short = len(text.strip()) < 10
    likely_question = any(q in text for q in ["ä½•", "ã©ã†", "ãªãœ", "ã„ã¤", "ã©ã“", "ã ã‚Œ", "èª°", "ã§ã™ã‹"])
    
    # æœªå®Œäº†æ–‡ã®ãƒã‚§ãƒƒã‚¯
    incomplete_markers = ["ã¯", "ãŒ", "ã‘ã©", "ã£ã¦", "ã¨ã‹", "ã®ã§", "ã‹ã‚‰"]
    ends_with_incomplete = any(text.strip().endswith(marker) for marker in incomplete_markers)
    
    # æ–‡æœ«è¡¨ç¾ã®ãƒã‚§ãƒƒã‚¯
    ending_particles = ["ã­", "ã‚ˆ", "ãª", "ã‚", "ã", "ãœ", "ã®ã ", "ã‚“ã "]
    has_ending_particle = any(text.strip().endswith(particle) for particle in ending_particles)
    
    # åˆ¤æ–­ãƒ­ã‚¸ãƒƒã‚¯
    if has_question_mark or likely_question:
        continue_conversation = False
        reason = "è³ªå•æ–‡ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
    elif ends_with_incomplete:
        continue_conversation = True
        reason = "æœªå®Œäº†ã®æ–‡ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
    elif has_ending_particle:
        continue_conversation = False
        reason = "æ–‡æœ«è¡¨ç¾ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
    elif is_short and not has_ending_particle:
        continue_conversation = True
        reason = "çŸ­ã„ç™ºè¨€ã§æ–‡æœ«è¡¨ç¾ãŒã‚ã‚Šã¾ã›ã‚“"
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å®Œäº†ã¨åˆ¤æ–­
        continue_conversation = False
        reason = "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: å®Œäº†ã—ãŸã¨åˆ¤æ–­"
    
    # é©åˆ‡ãªç›¸æ§Œã®ç”Ÿæˆ
    if continue_conversation:
        ack = "ã¯ã„"
    else:
        ack = "ãªã‚‹ã»ã©ã€ã‚ã‹ã‚Šã¾ã—ãŸ"
    
    return {
        "continueConversation": continue_conversation,
        "acknowledgement": ack,
        "reason": reason,
        "method": "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯"
    }

def parse_llm_response(response_text):
    """
    LLMå¿œç­”ã‚’è§£æã—ã¦JSONãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆã‚¨ãƒ©ãƒ¼å‡¦ç†æ”¹å–„ç‰ˆï¼‰
    """
    try:
        # ã¾ãšç›´æ¥JSONã¨ã—ã¦è§£æ
        try:
            # å¿œç­”ã‹ã‚‰JSONãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                data = json.loads(json_str)
                data["method"] = "JSONæ­£å¸¸è§£æ"
                return data
        except json.JSONDecodeError:
            pass
        
        # æ­£è¦è¡¨ç¾ã§å€‹åˆ¥ã«ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡º
        continue_match = re.search(r'"continueConversation"\s*:\s*(true|false)', response_text)
        ack_match = re.search(r'"acknowledgement"\s*:\s*"([^"]+)"', response_text)
        reason_match = re.search(r'"reason"\s*:\s*"([^"]+)"', response_text)
        
        if continue_match and ack_match:
            continue_conversation = continue_match.group(1).lower() == "true"
            ack = ack_match.group(1)
            reason = reason_match.group(1) if reason_match else "ç†ç”±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"
            
            return {
                "continueConversation": continue_conversation,
                "acknowledgement": ack,
                "reason": reason,
                "method": "æ­£è¦è¡¨ç¾è§£æ"
            }
            
        # ã™ã¹ã¦ã®è§£æãŒå¤±æ•—ã—ãŸå ´åˆã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚’ä½¿ç”¨
        return backup_heuristic_analysis(response_text)
    
    except Exception as e:
        # ãã‚Œã§ã‚‚å¤±æ•—ã—ãŸå ´åˆã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚’ä½¿ç”¨
        st.error(f"è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
        return backup_heuristic_analysis(response_text)

def main():
    st.set_page_config(
        page_title="ã‚¿ãƒ¼ãƒ³åˆ¤å®šãƒ†ã‚¹ã‚¿ãƒ¼",
        page_icon="ğŸ¤",
        layout="wide"
    )
    
    st.title("ğŸ¤ ã‚¿ãƒ¼ãƒ³åˆ¤å®šãƒ†ã‚¹ã‚¿ãƒ¼")
    st.subheader("ä¼šè©±ç¶™ç¶šåˆ¤å®šã®å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«")
    
    # LLMã®åˆæœŸåŒ–
    if "llm" not in st.session_state:
        with st.spinner("LLMã‚’åˆæœŸåŒ–ä¸­..."):
            try:
                st.session_state.llm = LLMManager()
                st.success("LLMã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
            except Exception as e:
                st.error(f"LLMã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.stop()
    
    # ã‚µã‚¤ãƒ‰ãƒ‘ãƒãƒ«ã«ã‚µãƒ³ãƒ—ãƒ«ä¾‹ã‚’è¡¨ç¤º
    with st.sidebar:
        st.header("ã‚µãƒ³ãƒ—ãƒ«ç™ºè¨€")
        
        examples = [
            "ã“ã‚“ã«ã¡ã¯",
            "ä»Šæ—¥ã®å¤©æ°—ã¯ã©ã†ã§ã™ã‹ï¼Ÿ",
            "ãã‚ŒãŒ",
            "ã‚ã®ã­",
            "æœ€è¿‘å¿™ã—ãã¦",
            "æ˜¨æ—¥æ˜ ç”»ã‚’è¦‹ã«è¡Œãã¾ã—ãŸ",
            "ãˆï¼Ÿ",
            "ãªã‚‹ã»ã©ã€ãã‚Œã§ï¼Ÿ",
            "äººå·¥çŸ¥èƒ½ã«ã¤ã„ã¦",
            "ã“ã®å‰è©±ã—ãŸä»¶ã«ã¤ã„ã¦ã€ã‚ã‚Œã¯ã©ã†ãªã‚Šã¾ã—ãŸã‹ï¼Ÿ"
        ]
        
        for example in examples:
            if st.button(example, key=f"example_{example}"):
                st.session_state.user_input = example
                st.rerun()
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢
    col1, col2 = st.columns([2, 3])
    
    with col1:
        st.subheader("ãƒ†ã‚¹ãƒˆå…¥åŠ›")
        
        # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
        user_input = st.text_area(
            "ç™ºè¨€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            value=st.session_state.get("user_input", ""),
            height=100,
            key="input_area"
        )
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        model = st.selectbox(
            "ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
            ["gemini-2.0-flash-lite", "gemini-2.0-flash", "gemini-1.5-flash", "claude-3-sonnet"],
            index=0
        )
        
        # ãƒ†ã‚¹ãƒˆãƒœã‚¿ãƒ³
        if st.button("åˆ¤å®šãƒ†ã‚¹ãƒˆ", use_container_width=True):
            if not user_input.strip():
                st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                st.session_state.user_input = user_input  # å†åˆ©ç”¨ã®ãŸã‚ã«ä¿å­˜
                with st.spinner("åˆ¤å®šä¸­..."):
                    # ã‚¿ãƒ¼ãƒ³åˆ¤å®šç”¨ã®LLMå‘¼ã³å‡ºã—
                    raw_response = st.session_state.llm.call_model(
                        prompt=user_input,
                        system_prompt=TURN_DETECTION_PROMPT,
                        model=model,
                        stream=False
                    )
                    
                    # å¿œç­”ã®è§£æ
                    parsed_result = parse_llm_response(raw_response)
                    
                    # æ¯”è¼ƒç”¨ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚‚å®Ÿè¡Œ
                    backup_result = backup_heuristic_analysis(user_input)
                    
                    # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                    st.session_state.raw_response = raw_response
                    st.session_state.parsed_result = parsed_result
                    st.session_state.backup_result = backup_result
                
                st.success("åˆ¤å®šå®Œäº†")
        
        # ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
        if st.button("ã‚¯ãƒªã‚¢", use_container_width=True):
            if "user_input" in st.session_state:
                del st.session_state.user_input
            if "raw_response" in st.session_state:
                del st.session_state.raw_response
            if "parsed_result" in st.session_state:
                del st.session_state.parsed_result
            if "backup_result" in st.session_state:
                del st.session_state.backup_result
            st.rerun()
        
        # è©³ç´°è¨­å®š
        with st.expander("è©³ç´°è¨­å®š"):
            st.text_area(
                "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º",
                value=TURN_DETECTION_PROMPT,
                height=300,
                key="custom_prompt"
            )
    
    with col2:
        st.subheader("åˆ¤å®šçµæœ")
        
        if "parsed_result" in st.session_state:
            # çµæœã‚’è¦–è¦šçš„ã«é­…åŠ›çš„ãªæ–¹æ³•ã§è¡¨ç¤º
            continue_conv = st.session_state.parsed_result.get("continueConversation", False)
            
            # ã‚«ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ã®çµæœè¡¨ç¤ºç”¨CSS
            st.markdown("""
            <style>
            .result-card {
                border-radius: 10px;
                padding: 20px;
                margin-bottom: 20px;
                box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            }
            .continue-true {
                background-color: #d1e7dd;
                border-left: 5px solid #198754;
            }
            .continue-false {
                background-color: #f8d7da;
                border-left: 5px solid #dc3545;
            }
            .comparison-card {
                background-color: #e2e3e5;
                border-left: 5px solid #6c757d;
            }
            </style>
            """, unsafe_allow_html=True)
            
            # ãƒ¡ã‚¤ãƒ³çµæœ
            st.markdown(
                f"""
                <div class="result-card {'continue-true' if continue_conv else 'continue-false'}">
                    <h3>{'âœ… ä¼šè©±ç¶™ç¶š' if continue_conv else 'ğŸ›‘ ä¼šè©±å®Œäº†'}</h3>
                    <p><strong>ç›¸æ§Œ/å¿œç­”:</strong> {st.session_state.parsed_result.get('acknowledgement', 'ãªã—')}</p>
                    <p><strong>åˆ¤æ–­ç†ç”±:</strong> {st.session_state.parsed_result.get('reason', 'ãªã—')}</p>
                    <p><strong>è§£ææ–¹æ³•:</strong> {st.session_state.parsed_result.get('method', 'ãªã—')}</p>
                </div>
                """, 
                unsafe_allow_html=True
            )
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã¨æ¯”è¼ƒ
            with st.expander("ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æ¯”è¼ƒ"):
                backup_continue = st.session_state.backup_result.get("continueConversation", False)
                agreement = backup_continue == continue_conv
                
                st.markdown(
                    f"""
                    <div class="result-card comparison-card">
                        <h4>{'âœ“ ä¸€è‡´' if agreement else 'âœ— ä¸ä¸€è‡´'}</h4>
                        <p><strong>ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯åˆ¤å®š:</strong> {'ä¼šè©±ç¶™ç¶š' if backup_continue else 'ä¼šè©±å®Œäº†'}</p>
                        <p><strong>ç†ç”±:</strong> {st.session_state.backup_result.get('reason', 'ãªã—')}</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                )
            
            # ç”Ÿã®LLMå¿œç­”
            with st.expander("ç”Ÿã®å¿œç­”"):
                st.code(st.session_state.raw_response)
            
            # å±¥æ­´
            if "history" not in st.session_state:
                st.session_state.history = []
            
            # ç¾åœ¨ã®çµæœã‚’å±¥æ­´ã«è¿½åŠ ï¼ˆæ–°ã—ã„å ´åˆï¼‰
            current_entry = {
                "input": st.session_state.user_input,
                "result": st.session_state.parsed_result
            }
            
            # æœ€æ–°ã®ã‚¨ãƒ³ãƒˆãƒªã§ãªã„å ´åˆã®ã¿è¿½åŠ 
            if not st.session_state.history or st.session_state.history[-1]["input"] != current_entry["input"]:
                st.session_state.history.append(current_entry)
            
            # å±¥æ­´ã®è¡¨ç¤º
            if st.session_state.history:
                with st.expander("å±¥æ­´", expanded=True):
                    for i, entry in enumerate(reversed(st.session_state.history[-10:])):
                        continue_val = entry["result"].get("continueConversation", False)
                        st.markdown(
                            f"""
                            <div style="margin-bottom:10px; padding:5px; border-left:3px solid {'green' if continue_val else 'red'}">
                                <strong>{"ä¼šè©±ç¶™ç¶š" if continue_val else "ä¼šè©±å®Œäº†"}:</strong> {entry["input"]}
                            </div>
                            """,
                            unsafe_allow_html=True
                        )
        else:
            st.info("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ã€Œåˆ¤å®šãƒ†ã‚¹ãƒˆã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")
    
    # ä½¿ã„æ–¹ã®èª¬æ˜
    st.markdown("---")
    st.markdown("""
    ### ä½¿ã„æ–¹
    1. å·¦å´ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«ç™ºè¨€ã‚’å…¥åŠ›ã™ã‚‹ã‹ã€ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ç™ºè¨€ã‚’é¸æŠã—ã¾ã™ã€‚
    2. ã€Œåˆ¤å®šãƒ†ã‚¹ãƒˆã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€LLMã«ã‚ˆã‚‹åˆ¤å®šçµæœã‚’ç¢ºèªã—ã¾ã™ã€‚
    3. å³å´ã«åˆ¤å®šçµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ç·‘è‰²ã¯ã€Œä¼šè©±ç¶™ç¶šã€ã€èµ¤è‰²ã¯ã€Œä¼šè©±å®Œäº†ã€ã‚’ç¤ºã—ã¾ã™ã€‚
    4. ã€Œå±¥æ­´ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§éå»ã®åˆ¤å®šçµæœã‚’ç¢ºèªã§ãã¾ã™ã€‚
    """)

if __name__ == "__main__":
    main() 